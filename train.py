import gymnasium as gym
from stable_baselines3 import DQN
from stable_baselines3.common.vec_env import DummyVecEnv
from stable_baselines3.common.callbacks import CheckpointCallback
import os

# Importe a classe que voc√™ criou
from dino_env import DinoEnv 

# --- Configura√ß√£o de Treinamento ---
# --- Configura√ß√£o de Treinamento ---
LOG_DIR = "./dino_tensorboard/"
MODEL_SAVE_PATH = "./dino_dqn_checkpoints/"
TOTAL_TIMESTEPS = 5_000_000 # <-- MUDAN√áA: 5 Milh√µes de passos
CHECKPOINT_FREQ = 100_000 

# Cria os diret√≥rios se n√£o existirem
os.makedirs(LOG_DIR, exist_ok=True)
os.makedirs(MODEL_SAVE_PATH, exist_ok=True)


# --- üöÄ IN√çCIO DA SELE√á√ÉO DE MODO ---
print("="*30)
print("ü§ñ ESCOLHA O MODO DE TREINAMENTO")
print("="*30)
print("   [1] Modo Lento (Vis√≠vel, para espiar)")
print("   [2] Modo R√°pido (Cego, para treinar)")
print("-"*30)
choice = input("Digite 1 ou 2 (padr√£o √© 2): ")

render_mode_choice = None
if choice == "1":
    render_mode_choice = "human"
    print("\nIniciando em MODO LENTO (vis√≠vel)...")
else:
    print("\nIniciando em MODO R√ÅPIDO (cego)...")
# --- FIM DA SELE√á√ÉO DE MODO ---


# 1. Crie o ambiente
env = DummyVecEnv([lambda: DinoEnv(render_mode=render_mode_choice)])


# --- üöÄ O C√âREBRO FINAL (INTELIG√äNCIA) ---

# Define a arquitetura do c√©rebro: [256 neur√¥nios, 256 neur√¥nios]
# (O padr√£o √© [64, 64]. O anterior era [128, 128])
policy_kwargs = dict(net_arch=[256, 256])

# 2. Crie o "c√©rebro" (o agente)
model = DQN(
    "MlpPolicy", 
    env, 
    policy_kwargs=policy_kwargs, # <-- ADICIONA O C√âREBRO GIGANTE
    verbose=1, 
    tensorboard_log=LOG_DIR,
    learning_rate=0.0001,
    buffer_size=1000000,         # Mem√≥ria (1 Milh√£o)
    learning_starts=100000,      # "Inf√¢ncia" longa (100k)
    batch_size=32,
    gamma=0.99,
    exploration_fraction=0.5,    # Explorar por 50% do tempo
    exploration_final_eps=0.01,
    train_freq=4,
    gradient_steps=1,
    target_update_interval=1000,
)

# ... (O resto do seu train.py est√° perfeito) ...

# Callback para salvar checkpoints
checkpoint_callback = CheckpointCallback(
    save_freq=CHECKPOINT_FREQ, 
    save_path=MODEL_SAVE_PATH, 
    name_prefix="dino_dqn_model"
)

print("--- O Treinamento vai come√ßar ---")
print(f"Salvando logs em: {LOG_DIR}")
print(f"Salvando modelos em: {MODEL_SAVE_PATH}")
print("Pressione CTRL+C para parar o treino (o progresso ser√° salvo no pr√≥ximo checkpoint).")


# 3. Mande o c√©rebro aprender!
try:
    model.learn(
        total_timesteps=TOTAL_TIMESTEPS,
        callback=checkpoint_callback
    )
except KeyboardInterrupt:
    print("\nTreinamento interrompido pelo usu√°rio.")

# 4. Salve o c√©rebro treinado final
model.save("dino_dqn_final")

print("--- Treinamento Conclu√≠do (ou interrompido) ---")
print(f"Modelo final salvo como 'dino_dqn_final.zip'")
env.close()